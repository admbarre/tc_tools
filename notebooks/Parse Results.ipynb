{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "sweet-congress",
   "metadata": {},
   "source": [
    "# Parse Results\n",
    "\n",
    "Using this right now to iterate through an experiment's directory and parse all the annotation result files\n",
    "and append them into one csv file per experiment.\n",
    "\n",
    "### Roadmap:\n",
    "1. Parse a **manual** results file and generate a dataframe from it\n",
    "2. Iterate an experiment directory, parse each **manual** result file and append to an experiment dataframe\n",
    "3. **DETOUR** Fix how we create and populate **automated anotations** for easier storage and reading\n",
    "4. Add in functionality to read in **automated annotations**\n",
    "5. Add in functionality to populate Google Sheets with results with **PROPER CHECKING FOR DUPLICATES**\n",
    "6. Get away from Google Sheets and use a proper database and visualization solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "velvet-adolescent",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "engaged-respondent",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_dir = \"/Volumes/the_box/CURRENT ANNOTATIONS/\"\n",
    "\n",
    "single_cell_dir = \"10-22 Jurkat TNFa varying on rates\"\n",
    "triple_cell_dir = \"10-21 varying on JTIC16\"\n",
    "\n",
    "experiment_dir = f\"{annotations_dir}/{triple_cell_dir}\"\n",
    "\n",
    "lane_dirs = [file for file in os.listdir(experiment_dir) if os.path.isdir(file)]\n",
    "\n",
    "test_lane = \"LN1_2\"\n",
    "\n",
    "current_dir = f\"{experiment_dir}/{test_lane}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "colonial-brave",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_cols = [\"Date\", \"Name\", \"Lane\", \"Lag Binder\", \"ICD\", \"Cell\", \"Counts\", \"Sum\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ahead-string",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using this to populate database row entries\n",
    "# Need to read in notes file to get other info maybe?\n",
    "def get_info(results_dir):\n",
    "    tokens = results_dir.split(\"/\")\n",
    "    lane = tokens[-1]\n",
    "    lane_prefix, lane_number = lane.split(\"_\")\n",
    "    std_lane_prefix = \"LN\"\n",
    "    corrected_lane = f\"{std_lane_prefix}_{lane_number}\"\n",
    "\n",
    "    date_name = tokens[-2]\n",
    "    \n",
    "    date_name_tokens = date_name.split(\" \")\n",
    "    date = date_name_tokens[0]\n",
    "    name = \" \".join(date_name_tokens[1:])\n",
    "    print(f\"Date: {date} Name: {name} Lane: {std_lane_prefix}{lane_number}\")\n",
    "    info = [date,name,corrected_lane]\n",
    "    return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "apart-equilibrium",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_results(lane_dir):\n",
    "    manual_dir = \"manual/results\"\n",
    "    results_dir = f\"{lane_dir}/{manual_dir}\"\n",
    "    # Does changing dir revert back function ends? Should use that instead of specifying full path each time\n",
    "    print(f\"Reading from: {results_dir}\")\n",
    "    results_file = [f for f in os.listdir(results_dir) if f.endswith(\".csv\")][0]\n",
    "    #print(results_file)\n",
    "    results = pd.read_csv(f\"{results_dir}/{results_file}\")\n",
    "    coi = get_columns_of_interest(results)\n",
    "    parsed = parse_results(results,coi)\n",
    "    return parsed\n",
    "\n",
    "# This reads the Cell Counter results table and gets the column names we are interested in\n",
    "def get_columns_of_interest(results):\n",
    "    r_cols = list(results.columns)\n",
    "    cpos_index = r_cols.index(\"C-pos\")\n",
    "    channel = r_cols[cpos_index - 1]\n",
    "    cells = r_cols[1:cpos_index-1]\n",
    "    position = r_cols[cpos_index+1]\n",
    "    cols_of_interest = cells + [channel,position]\n",
    "    return cols_of_interest\n",
    "\n",
    "# This uses the columns of interest and gets the results while renaming them\n",
    "def parse_results(results, coi):\n",
    "    coi = get_columns_of_interest(results)\n",
    "    \n",
    "    filtered = pd.DataFrame(results[coi])\n",
    "    ch_col_old_name = list(filtered.columns)[-2]\n",
    "    col_swaps = {ch_col_old_name: \"Channel\", \"Z-pos\": \"Position\"}\n",
    "    parsed = filtered.rename(columns=col_swaps)\n",
    "    return parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "decent-blame",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This reads the cleaned results table and extracts cell counts while accounting for annotation erros\n",
    "def get_cell_pos_counts(cell_name, results):\n",
    "    cell = results[[cell_name,\"Position\"]]\n",
    "    cell_positions = cell.groupby(\"Position\")\n",
    "    cell_pos_counts = [sum(pos[1][cell_name]) for pos in cell_positions]\n",
    "    return cell_pos_counts\n",
    "\n",
    "# Need to output csv rows of the form\n",
    "# Date Name Lane LagBinder ICD CellName CountsList Sum\n",
    "# 10-21 varying on rates L16 ICAM  L16 ICAM  32 22 32 86\n",
    "def generate_db_rows(current_dir):\n",
    "    info = get_info(current_dir)\n",
    "    results = read_results(current_dir)\n",
    "    cells = list(results.columns[:-2])\n",
    "\n",
    "    # Need to figure out how to handle cell counts as either a list or a string to fit into one cell\n",
    "    db_rows = [info + expand_cell_name(cell) + [get_cell_pos_counts(cell,results)] for cell in cells]\n",
    "    return db_rows\n",
    "\n",
    "def expand_cell_name(cell):\n",
    "    lag_binders = [\"L\"+ str(num) for num in [16,17,42,18]]\n",
    "    icds = [\"ICAM\", \"PSGL1 Tether\", \"ICAM Tether\"]\n",
    "    \n",
    "    cell_tokens = cell.split(\" \")\n",
    "    #print(cell_tokens)\n",
    "    \n",
    "    # Initializing, probably better way to do this\n",
    "    binder = icd = name = \"\"\n",
    "    \n",
    "    # Just to accomodate some annotation names\n",
    "    jurkats = [\"Jurkat\", \"Jurkats\"]\n",
    "    # Jurkat case\n",
    "    for j in jurkats:\n",
    "        if j in cell_tokens:\n",
    "            #print(\"Jurkat found\")\n",
    "            binder = \"none\"\n",
    "            icd = \"Jurkat\"\n",
    "            name = \"Jurkat\"\n",
    "            return [binder,icd,name]\n",
    "        \n",
    "    # Other cells\n",
    "    for t in cell_tokens:\n",
    "        #print(f\"Checking {t}...\")\n",
    "        if t in lag_binders:\n",
    "            print(\"Found\")\n",
    "            binder = t\n",
    "\n",
    "            # Trim out binder to parse ICD\n",
    "            cell_tokens.remove(t)\n",
    "        else:\n",
    "            # This shouldn't happen\n",
    "            binder = \"error\"\n",
    "                \n",
    "    # Checking for our ICDs\n",
    "    icd_candidate = \" \".join(cell_tokens)\n",
    "    #print(f\"Checking {icd_candidate}\")\n",
    "    if icd_candidate in icds:\n",
    "        #print(\"Found\")\n",
    "        icd = icd_candidate\n",
    "    else:\n",
    "        # This should never happen\n",
    "        icd = \"error?\"\n",
    "                \n",
    "    # Rebuilding name in standard order        \n",
    "    name = f\"{binder} {icd}\"\n",
    "        \n",
    "    #print(f\"Lag Binder: {binder} ICD: {icd} Name: {name}\")\n",
    "    return [binder,icd,name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "settled-suffering",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date: 10-21 Name: varying on JTIC16 Lane: LN2\n",
      "Reading from: /Volumes/the_box/CURRENT ANNOTATIONS//10-21 varying on JTIC16/LN1_2/manual/results\n",
      "Found\n",
      "['10-21', 'varying on JTIC16', 'LN_2', 'none', 'Jurkat', 'Jurkat', [0, 0, 0]]\n",
      "['10-21', 'varying on JTIC16', 'LN_2', 'error', 'PSGL1 Tether', 'error PSGL1 Tether', [8, 10, 9]]\n",
      "['10-21', 'varying on JTIC16', 'LN_2', 'L16', 'ICAM', 'L16 ICAM', [32, 22, 32]]\n"
     ]
    }
   ],
   "source": [
    "rows = generate_db_rows(current_dir)\n",
    "for r in rows:\n",
    "    print(r)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
